{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/omer/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data & formatting\n",
    "\n",
    "Xraw = pd.read_csv('/Users/omer/Documents/YK Data/X.csv', index_col=0, dtype=\"category\")\n",
    "Yraw = pd.read_csv('/Users/omer/Documents/YK Data/Y.csv', index_col=0)\n",
    "X = Xraw.to_numpy()\n",
    "Y = Yraw.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test sets\n",
    "\n",
    "train_size = int(len(X) * 0.8) \n",
    "test_size  = len(X) - train_size \n",
    "X_train, X_test = X[0:train_size,:], X[train_size:len(X), :]\n",
    "Y_train, Y_test = Y[0:train_size,:], Y[train_size:len(Y), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate class weight to accomaodate for imbalance\n",
    "\n",
    "Ydf = pd.DataFrame(Y_train,index=Y_train[:,0])\n",
    "y_classes = Ydf.idxmax(1)\n",
    "le = LabelEncoder()\n",
    "le.fit(list(y_classes))\n",
    "y_integers = le.transform(list(y_classes))\n",
    "labels_and_integers = dict(zip(y_classes, y_integers))\n",
    "class_weights = compute_class_weight('balanced', np.unique(y_integers), y_integers)\n",
    "sample_weights = compute_sample_weight('balanced', y_integers)\n",
    "\n",
    "class_weights_dict = dict(zip(le.transform(list(le.classes_)), class_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/omer/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#learn embeddings -- train\n",
    "\n",
    "model_embed = Sequential()\n",
    "model_embed.add(Embedding(140, 1, input_length=1578))\n",
    "model_embed.compile('Adam', 'categorical_crossentropy')\n",
    "X_train_embedded = model_embed.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#learn embeddings -- test\n",
    "\n",
    "model_embed = Sequential()\n",
    "model_embed.add(Embedding(140, 1, input_length=1578))\n",
    "model_embed.compile('Adam', 'categorical_crossentropy')\n",
    "X_test_embedded = model_embed.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape for LSTM\n",
    "\n",
    "X_train3 = np.reshape(X_train_embedded,(X_train_embedded.shape[0], 1, X_train.shape[1]))\n",
    "X_test3  = np.reshape(X_test_embedded,(X_test_embedded.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "\n",
    "model_lstm = Sequential()\n",
    "\n",
    "model_lstm.add(LSTM(units=256, input_shape = (1,1578), dropout = 0.3, recurrent_dropout = 0.3))\n",
    "model_lstm.add(Dense(256, activation = 'relu'))\n",
    "model_lstm.add(Dropout(0.3))\n",
    "model_lstm.add(Dense(53, activation = 'softmax'))\n",
    "model_lstm.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=[tf.keras.metrics.Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6467 samples, validate on 1617 samples\n",
      "Epoch 1/5\n",
      "6467/6467 [==============================] - 35s 5ms/step - loss: 1.3142 - recall_1: 0.5695 - val_loss: 1.2093 - val_recall_1: 0.6209\n",
      "Epoch 2/5\n",
      "6467/6467 [==============================] - 36s 6ms/step - loss: 1.1445 - recall_1: 0.6197 - val_loss: 1.1772 - val_recall_1: 0.6257\n",
      "Epoch 3/5\n",
      "6467/6467 [==============================] - 21s 3ms/step - loss: 1.1175 - recall_1: 0.6294 - val_loss: 1.1808 - val_recall_1: 0.6290\n",
      "Epoch 4/5\n",
      "6467/6467 [==============================] - 22s 3ms/step - loss: 1.1030 - recall_1: 0.6297 - val_loss: 1.1766 - val_recall_1: 0.6311\n",
      "Epoch 5/5\n",
      "6467/6467 [==============================] - 23s 4ms/step - loss: 1.0929 - recall_1: 0.6328 - val_loss: 1.1583 - val_recall_1: 0.6338\n"
     ]
    }
   ],
   "source": [
    "#fit the model model\n",
    "\n",
    "h = model_lstm.fit(X_train3, Y_train, validation_split=0.2, verbose=1, epochs=5, batch_size=10, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make predictions\n",
    "\n",
    "train_predict = model_lstm.predict(X_train3)\n",
    "test_predict  = model_lstm.predict(X_test3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train[[23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.051 0.173 0.08  0.325 0.068 0.02  0.034 0.002 0.    0.    0.007 0.033\n",
      "  0.005 0.    0.    0.033 0.006 0.003 0.02  0.    0.023 0.01  0.    0.\n",
      "  0.    0.04  0.001 0.    0.007 0.    0.001 0.    0.007 0.    0.003 0.\n",
      "  0.002 0.    0.009 0.002 0.    0.    0.007 0.019 0.    0.    0.001 0.003\n",
      "  0.004 0.    0.    0.    0.001]]\n"
     ]
    }
   ],
   "source": [
    "print (train_predict[[990]].round(decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print (len(np.unique(y_integers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print (Y_train[[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.60174361]\n"
     ]
    }
   ],
   "source": [
    "print (sample_weights[[23]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast_2:0\", shape=(8084,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.1132964e-05, 5.0477274e-06, 2.1648123e-08, 8.1232523e-05,\n",
       "        2.6170997e-02, 9.7367913e-01, 6.4839227e-09, 1.4643424e-10,\n",
       "        2.2489919e-09, 1.7345250e-09, 1.3180698e-10, 1.6093573e-07,\n",
       "        3.5240680e-07, 8.5104715e-11, 2.7130259e-08, 1.9890789e-09,\n",
       "        2.0272937e-12, 1.3184450e-09, 5.3039451e-10, 4.7114646e-10,\n",
       "        7.8823323e-11, 3.7944175e-12, 9.7913699e-10, 1.4037573e-07,\n",
       "        5.0944413e-07, 3.0060676e-07, 5.2274172e-09, 5.9216645e-06,\n",
       "        1.5515261e-10, 5.2484830e-07, 3.5815390e-10, 1.4395304e-09,\n",
       "        8.1494314e-09, 3.6166558e-08, 1.6632973e-10, 3.2424794e-09,\n",
       "        4.0044371e-10, 1.2779539e-09, 1.1972772e-09, 1.6128829e-06,\n",
       "        4.6798448e-08, 2.1439709e-08, 1.7581948e-12, 6.9597930e-12,\n",
       "        4.2803094e-09, 1.5456793e-08, 3.3644594e-11, 1.4472389e-09,\n",
       "        1.7857438e-07, 1.0669618e-06, 7.6953829e-06, 3.7362572e-06,\n",
       "        3.6850237e-10]], dtype=float32)"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[[123]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
